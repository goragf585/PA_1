### ===============
import pandas as pd

# pip install streamlit
import streamlit as sl

from PIL import Image

#from sklearn import datasets
#iris = datasets.load_iris()

import matplotlib as mpl
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure

import seaborn as sb

import numpy as np

from bokeh.io import push_notebook, show, output_notebook
from bokeh.layouts import row
from bokeh.plotting import figure, show
#output_notebook()
from bokeh.palettes import Category20c
from bokeh.transform import cumsum

from math import pi

# pip install statsmodels
from statsmodels import robust

from pathlib import Path
import random

from scipy import stats
import statsmodels.api as sm
from scipy.stats import mannwhitneyu

import statsmodels.formula.api as smf
from statsmodels.stats import power
### ===============

### ===============
def begin_Visualization():
    sl.caption("**Version:** _0.3_")
    
    ###
    sl.caption("Innopolis University Logotypes:")
    
    #col_0, col_1 = sl.columns(2, gap = "large")
    col_0, col_1 = sl.columns([1, 1], gap = "large")
    
    with col_0:
        #logo_1 = Image.open("logo_1.png")
        # w = 431, h = 101
        #sl.image(logo_1, caption = "")
        
        # ! –°–¥–µ–ª–∞—Ç—å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –ø–æ –Ω–∏–∂–Ω–µ–º—É –∫—Ä–∞—é
        #placeholder = sl.empty()
        sl.caption("")
        sl.caption("")
        sl.caption("")
        sl.caption("")
        sl.caption("")
        sl.caption("")
        sl.caption("")
        sl.caption("")
        
        sl.image("https://upload.wikimedia.org/wikipedia/commons/4/48/–õ–û–ì–û–¢–ò–ü_–£–ò.svg", caption = "New")
        #, width = 431)
    
    with col_1:
        logo_0 = Image.open("logo_0.png")
        # w = 1338, h = 813
        sl.image(logo_0, caption = "Old") #, width = 134)

    ###
    sl.write("---") # or "---" (only in StreamLit)

    ###
    sl.title("–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–∞—è –∞—Ç—Ç–µ—Å—Ç–∞—Ü–∏—è ‚Ññ _1_")

    ###
    sl.markdown("**–§. –ò. –û.:** _C–µ–Ω—á–∏–ª–æ –ü. –í._;")
    sl.markdown("**–ü–ê** ‚Ññ: `001` = **–ë–ª–æ–∫** ‚Ññ `1`;")
    sl.markdown("**–î–∞—Ç–∞:** `2023-08-15`.")

    ###
    #sl.image("https://upload.wikimedia.org/wikipedia/commons/8/83/Iris_germanica_160505.jpg", 
    #caption = "Iris Germanica")

    ###
    sl.divider()

### ===============
def load_DF():
    spoiler = "Expand / Collapse ..."
    
    ###
    sl.markdown("**_Iris_ Data-Set Link:** https://www.kaggle.com/datasets/uciml/iris")
    sl.text("... or...")
    sl.code(body = "from sklearn import datasets \niris = datasets.load_iris()", language = "python", line_numbers = True)
    sl.code(body = "$ streamlit run _.py", language = "python", line_numbers = True)
    sl.divider()
    
    ### === 0. UpLoading a File:
    # Limit 200MB per file. File must be 200.0MB or smaller.
    sl.header("Step _1_. üìé")
    f_uploaded = sl.file_uploader("**Please, pick a Data-Set-containing File:**")
    if (f_uploaded is not None):
        # To See File Details:
        f_details = {
            "File Name": f_uploaded.name, 
            "File Type": f_uploaded.type,
            "File Size": f_uploaded.size } # (–±–∞–π—Ç)
        sl.write("**The Picked File Details:**")
        sl.write(f_details)
        sl.write("**- [File] MIME-Type:**", f_details["File Type"], "=", f_uploaded.type)
        f_type = f_uploaded.type
        
        #
        #sl.write("**-- [MIME-Type]: Name Type & Supported Methods:**")
        #with sl.expander(spoiler, expanded = False):
        #    sl.write(type(f_type))
        #

    ### === 1. Checking the File Type:
        if (f_type != "text/csv"):
            sl.write(":red[**InPut Error:** Please, select a CSV-File instead!]")
            sl.markdown(":red[**UnicodeDecodeError:** 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte]")
        else:
            sl.write(":green[**InPut's OK:** The CSV-File with Data-Set has been uploaded successfully]")
        
        ### === 2. Viewing the DataSet:

            ### A. Pandas Data-Frame:
            #DS_f_name = "data_sets/Iris.csv" #
            #sl.text("The Selected Data-Set [CSV-File] Path + Name = " + DS_f_name) #
            #DF_PD = pd.read_csv(DS_f_name)
            
            ###
            #sl.subheader("A. ) Pandas Data-Frame OutPut:")
            #with sl.expander(spoiler, expanded = True):
            #    DF_PD
            
            ### B. StreamLit Data-Frame (Pandas):
            # Can be used wherever a "file-like" object is accepted:
            DF_SL = pd.read_csv(f_uploaded)
            #DF_SL = sl.dataframe(data = f_uploaded)
            
            ###
            sl.subheader("B. Streamlit Data-Frame OutPut Methods:")
            with sl.expander(spoiler, expanded = False):
                col_a = "DataFrame"
                col_b = "Write"
                col_c = "Table"
                tab_a, tab_b, tab_c = sl.tabs([col_a, col_b, col_c])
                
                with tab_a:
                    sl.subheader("_.a) `" + col_a + "`:")
                    sl.dataframe(DF_SL)
                
                with tab_b:
                    sl.subheader("_.b) `" + col_b + "`:")
                    sl.write(DF_SL)
                
                with tab_c:
                    sl.subheader("_.c) `" + col_c + "`:")
                    sl.table(DF_SL)
            
            ###
            DF_cols_names = list(DF_SL.columns.values) #list(DF_PD)
            sl.write("**Data-Frame Columns' Names:**", DF_cols_names)
            # = ["Id", "SepalLengthCm", "SepalWidthCm", "PetalLengthCm", "PetalWidthCm", "Species"]
            DF_cols_num = len(DF_cols_names)
            sl.write("**=> –í—Å–µ–≥–æ —Å—Ç–æ–ª–±—Ü–æ–≤:**", DF_cols_num)
            DF_rows_num = len(DF_SL)
            sl.write("**=> –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫:**", DF_rows_num)
            
            ###
            #DF_cols_ru = ["‚Ññ ", "–î.( –ß.) (—Å–º)", "–®.( –ß.) (—Å–º)", "–î.( –õ.) (—Å–º)", "–®.( –õ.) (—Å–º)", "–í–∏–¥—ã —Ä–æ–¥–∞ –ò—Ä–∏—Å"]
            #sl.write("**–ü–µ—Ä–µ–≤–æ–¥ –∏—Ö –Ω–∞–∑–≤–∞–Ω–∏–π:**")
            #sl.write("// (–î. = –î–ª–∏–Ω–∞, –®. = –®–∏—Ä–∏–Ω–∞; –ß. = –ß–∞—à–µ-–ª–∏—Å—Ç–∏–∫, –õ. = –õ–µ–ø–µ—Å—Ç–æ–∫)", DF_cols_ru)
            
            ###
            select_DF_cols(DF_SL, DF_cols_names)

### ===============
def select_DF_cols(DF, DF_cols_names): 
    sl.divider()
    
    ### === 0. Selecting Data-Frame Columns:       
    sl.header("Step _2_. ‚òëÔ∏è")
    sl.write("**Please, select _2_ Data-Frame Columns, _1_ by _1_:**")

    ### = Multi-Selection:
    sl.write("// –ü—Ä–æ—Å—Ç–æ –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–µ—Ç–æ–¥–∞ `MultiSelection`:")
    sel_col_1, sel_col_2 = sl.multiselect(label = "**Columns** ‚Ññ‚Ññ _1_ & _2_:", options = DF_cols_names, default = [DF_cols_names[1], DF_cols_names[2]], max_selections = 2, placeholder = "Choose _2_ Columns", disabled = True, label_visibility = "visible") # 
    # ValueError: not enough values to unpack (expected 2, got 0)

    sl.write("// –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –≤—ã–±—Ä–∞–Ω—ã _2_ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏.")
    sl.write("// –ß—Ç–æ–±—ã –Ω–µ —Ç—Ä–∞—Ç–∏—Ç—å –ª–∏—à–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ –æ–∂–∏–¥–∞–Ω–∏–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –ø–æ —Å—Ç–æ–ª–±—Ü—É `Id`, ")
    sl.write("//  –≤ –≤–µ—Ä—Ö–Ω–µ–º –ø—Ä–∞–≤–æ–º —É–≥–ª—É –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –º–æ–∂–Ω–æ –Ω–∞–∂–∞—Ç—å –Ω–∞ –∫–Ω–æ–ø–∫—É `Stop` ")
    sl.write("//  –∏ —Å—Ä–∞–∑—É –≤—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥–æ–π (–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π) —Å—Ç–æ–ª–±–µ—Ü.")
    
    ### = Drop-Down _1_
    sel_col_1_name = sl.selectbox(label = "**Column** ‚Ññ _1_:", options = DF_cols_names)#, key = "c1")
    
    #sl.write(type(sel_col_1_name)) # => load_DF() classbuiltins.str(...)
    
    ### = Drop-Down _2_
    sel_col_2_name = sl.selectbox(label = "**Column** ‚Ññ _2_:", options = DF_cols_names, index = 0)#, key = "c2")

    sl.write("**Your selected Columns:**", sel_col_1_name, "&", sel_col_2_name)
    
    ### === 1. Checking if they are not the same:
    if (sel_col_1_name == sel_col_2_name):
        sl.write(":red[**InPut Error:** Please, select _2_ different Data-Frame Columns (change _1_ of them)!]")
    else:
        sl.write(":green[**InPut's OK:** The _2_ selected Data-Frame Columns are different]")
        plot_Distribution(DF, DF_cols_names, sel_col_1_name, sel_col_2_name) 

### =============== ===============
def is_Categorial(DF, sel_col_name): 
    # datetime = ?
    T_cat_types = ("category", "object", "string")
    F_cat_types = ("float", "float64")
    X_cat_types = ("int", "int64")
    
    DF_cols_names = list(DF.columns.values) # –ó–∞–Ω–æ–≤–æ!
    sel_col_i = DF_cols_names.index(sel_col_name)
    sel_col_type = DF.dtypes[sel_col_i].name
    sl.write("**Column** [", sel_col_name, "] **Type** is:", sel_col_type)   

    sl.write("=> Column [", sel_col_i, "] Values are:")
    if (sel_col_type in F_cat_types):
        is_cat_sel_col = False
        sl.write("Not Categorical.")
    elif (sel_col_type in T_cat_types):
        is_cat_sel_col = True
        sl.write("    Categorical.")
    else:
        is_cat_sel_col = True #
        sl.write("??? Categorical.")
    return is_cat_sel_col

### =============== ===============
def if_Charts_or_Hist(DF, sel_col_name, is_cat_sel_col):
    if (is_cat_sel_col == True):
        plot_Charts(DF, sel_col_name)
    elif (is_cat_sel_col == False):
        plot_Hist(DF, sel_col_name)
 
### =============== ===============
def plot_Charts(DF, sel_col_name):
    sl.write("**=> Plot _2_ Charts:**", sel_col_name)
 
    sl.write("**:orange[–ì—Ä–∞—Ñ–∏–∫–∏ `Bokeh` –æ—Ç–∫—Ä—ã–≤–∞—é—Ç—Å—è –≤ –Ω–æ–≤—ã—Ö –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –≤–∫–ª–∞–¥–∫–∞—Ö (`Bokeh Plot`)!]**")
    sl.code(body = "file:///C:/Temp/_.html", language = "python", line_numbers = True) 
 
    ### 1. –°—Ç–æ–ª–±—á–∞—Ç–∞—è –î–∏–∞–≥—Ä–∞–º–º–∞
    
    # 4.2 = SeaBorn 2
    sb_bar = sb.countplot(x = sel_col_name, data = DF)
    plt.title("–°—Ç–æ–ª–±—á–∞—Ç–∞—è –î–∏–∞–≥—Ä–∞–º–º–∞ (SeaBorn)")
    #plt.show()
    sl.pyplot()
    
    # 5.0 = Bokeh
    values = list(set(DF[sel_col_name]))
    counts = DF[sel_col_name].value_counts()
    p = figure(x_range = values, height = 350, title = "–°—Ç–æ–ª–±—á–∞—Ç–∞—è –î–∏–∞–≥—Ä–∞–º–º–∞ (Bokeh)", toolbar_location = None, tools = "")
    p.vbar(x = values, top = counts, width = 0.8)
    p.xgrid.grid_line_color = None
    p.y_range.start = 0
    show(p)    
    ######
    
    ### 2. –ö—Ä—É–≥–æ–≤–∞—è –î–∏–∞–≥—Ä–∞–º–º–∞
    # 1.1 = Pandas 1
    pd_pie = DF[sel_col_name].value_counts().plot(kind = 'pie', figsize = (6, 6), autopct = '%1.2f%%')
    plt.title("–ö—Ä—É–≥–æ–≤–∞—è –î–∏–∞–≥—Ä–∞–º–º–∞ (Pandas)")
    plt.xlabel("")
    plt.ylabel("") 
    #plt.show()
    sl.pyplot()
    
    # 5.0 = Bokeh
    pd_ser = DF[sel_col_name].value_counts()#.values = [50 50 50], <class 'numpy.ndarray'>
    sl.write(pd_ser)
    #spoiler = "Expand / Collapse ..."
    #with sl.expander(spoiler, expanded = False):    
    #    sl.write("Type of [pd_ser]:", type(pd_ser))
    data = pd_ser.reset_index(name = 'value').rename(columns = {'index': 'Species'}) #
    data['angle'] = ( data['value']/data['value'].sum() ) * 2*pi
    data['color'] = Category20c[len(pd_ser)]
    p = figure(height = 350, title = "Pie Chart (Bokeh)", toolbar_location = None,
               tools = "hover", tooltips = "@Species: @value", x_range = (-0.5, 1.0)) #
    p.wedge(x = 0, y = 1, radius = 0.4, 
            start_angle = cumsum('angle', include_zero = True), end_angle = cumsum('angle'),
            line_color = "white", fill_color = 'color', legend_field = 'Species', source = data) #
    p.axis.axis_label = None
    p.axis.visible = False
    p.grid.grid_line_color = None
    show(p)    
    ######
    
    #sl.write("**:orange[–ì—Ä–∞—Ñ–∏–∫–∏ `Bokeh` –æ—Ç–∫—Ä—ã–≤–∞—é—Ç—Å—è –≤ –Ω–æ–≤—ã—Ö –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –≤–∫–ª–∞–¥–∫–∞—Ö (`Bokeh Plot`)!]**")
    #sl.code(body = "file:///C:/Temp/_.html", language = "python", line_numbers = True)    
    ######
    
### =============== ===============
def plot_Hist(DF, sel_col_name): # DF_rows_num
    sl.write("**=> Plot _a_ Hist:**", sel_col_name)
    DF_rows_num = len(DF) # = –ó–∞–Ω–æ–≤–æ!
    
    ### 0. –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ 
    # 2.1 = MatPlotLib 1
    mpl_hist = plt.hist(DF[sel_col_name], bins = DF_rows_num)
    plt.title("–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ (MatPlotLib)")
    plt.xlabel(sel_col_name)
    plt.ylabel("–ß–∞—Å—Ç–æ—Ç–∞")
    #plt.show()
    sl.pyplot()
    
    sl.text("Data_Frame[sel_col_name]:\n")
    sl.text(DF.describe()[sel_col_name])

### ===============    
def plot_Distribution(DF, DF_cols_names, sel_col_1_name, sel_col_2_name):
    sl.divider()
    
    ### === 0. Viewing the selected Data-Frame Columns' Types:
    sl.header("Step _3_. üìä")
    sl.write("**Plotting the selected Data-Frame Columns' Data:**")
    
    sl.write("**All of the Data-Frame Columns' Types:**")
    sl.text(DF.dtypes)
    
    ### === 1. Checking if the selected Columns are Categorical or non-:
    
    #sel_col_1_i = DF_cols_names.index(sel_col_1_name)
    is_cat_sel_col_1 = is_Categorial(DF, sel_col_1_name)
    
    #sel_col_2_i = DF_cols_names.index(sel_col_2_name)
    is_cat_sel_col_2 = is_Categorial(DF, sel_col_2_name)
    
    ### === 2. Depending on if they are Categorical, plot a Bar-Chart or a HistoGram:
    sl.set_option('deprecation.showPyplotGlobalUse', False)
    sl.write("- - -")
    sl.write("**1.**")
    if_Charts_or_Hist(DF, sel_col_1_name, is_cat_sel_col_1)
    sl.divider()
    sl.write("**2.**")
    if_Charts_or_Hist(DF, sel_col_2_name, is_cat_sel_col_2)
    # -->
    summary_1()
    
    # -->
    stat_hip(DF, sel_col_1_name, sel_col_2_name)  

### ===============
def summary_1():
    sl.divider()
    sl.markdown(body = "**–í—ã–≤–æ–¥—ã (1):**")
    sl.markdown(body = "**0. –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ**")
    sl.markdown(body = "–í –∫–∞—á–µ—Å—Ç–≤–µ –ø—Ä–∏–º–µ—Ä–∞ –≤–æ–∑—å–º—ë–º **DataSet** `Iris`")
    sl.markdown(body = " –∏, –≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏, –≤—ã–±–µ—Ä–µ–º –µ–≥–æ **—Å—Ç–æ–ª–±—Ü—ã** `SepalLengthCm` (–î–ª–∏–Ω–∞ —á–∞—à–µ–ª–∏—Å—Ç–∏–∫–∞, —Å–º) –∏ `Species` (–í–∏–¥—ã).")
    sl.markdown(body = "(–ù–µ—Ç —Å–º—ã—Å–ª–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å **—Å—Ç–æ–ª–±–µ—Ü** `Id`, —Ç. –∫. –æ–Ω —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–æ—Å—Ç–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–æ–∫")
    sl.markdown(body = " (–æ–ø–∏—Å–∞–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ, –æ—Ç–¥–µ–ª—å–Ω–æ –≤–∑—è—Ç–æ–≥–æ —Ä–∞—Å—Ç–µ–Ω–∏—è, –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—â–µ–≥–æ —Ä–æ–¥—É –ò—Ä–∏—Å.)")
    sl.markdown(body = "–í—Å–µ–≥–æ –≤ —ç—Ç–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö -- `6` **—Å—Ç–æ–ª–±—Ü–æ–≤** –∏ `150` **—Å—Ç—Ä–æ–∫**.")
    sl.markdown(body = "**1. –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–æ—Å—Ç—å**")
    sl.markdown(body = "–ó–Ω–∞—á–µ–Ω–∏—è `SepalLengthCm` -- –Ω–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ (—á–∏—Å–ª–∞), —Ç. –∫. —ç—Ç–æ -- –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ —Å–ª—É—á–∞–π–Ω—ã–µ –≤–µ–ª–∏—á–∏–Ω—ã,") 
    sl.markdown(body = " –∞ `Species` -- –Ω–∞–æ–±–æ—Ä–æ—Ç, –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ (—Å—Ç—Ä–æ–∫–∏), —Ç. –∫. –æ–Ω–∏ -- –ø—Ä–µ—Ä—ã–≤–Ω—ã–µ (–¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ).")
    sl.markdown(body = "**2. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è:**")
    sl.markdown(body = "–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ, –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ —Å—Ç—Ä–æ–∏–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, ")
    sl.markdown(body = " –∞ –¥–ª—è –Ω–µ_–∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö -- —Å—Ç–æ–ª–±—á–∞—Ç—É—é –∏–ª–∏ –∫—Ä—É–≥–æ–≤—É—é –¥–∏–∞–≥—Ä–∞–º–º—É.")
    sl.markdown(body = "**2.1. `SepalLengthCm`**")
    sl.markdown(body = "–ü–æ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–µ –≤–∏–¥–Ω–æ, —á—Ç–æ **–∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã —á–∞—à–µ–ª–∏—Å—Ç–∏–∫–∞**:")
    sl.markdown(body = "- **—Å—Ä–µ–¥–Ω–µ–µ**      -- `—Ä–∞–≤–Ω–æ–µ –ø—Ä–∏–º–µ—Ä–Ω–æ` `5.84(3333)` —Å–∞–Ω—Ç–∏–º–µ—Ç—Ä–∞–º, ")
    sl.markdown(body = "- **–º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ**  -- `—Ä–∞–≤–Ω–æ` `4.3` —Å–º;")
    sl.markdown(body = "- **–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ** -- `—Ä–∞–≤–Ω–æ` `7.9` —Å–º.")
    sl.markdown(body = "**2.2. `Species`**")
    sl.markdown(body = "–ü–æ –¥–∏–∞–≥—Ä–∞–º–º–∞–º –≤–∏–¥–Ω–æ, —á—Ç–æ –≤ —Ç–∞–±–ª–∏—Ü–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –∏—Ä–∏—Å—ã –≤—Å–µ–≥–æ `3`—Ö –≤–∏–¥–æ–≤,")
    sl.markdown(body = " –∏ –∫–∞–∂–¥—ã–π –∏–∑ –Ω–∏—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –∑–¥–µ—Å—å `—Ä–æ–≤–Ω–æ` ") 
    sl.latex(body = "150/3 = 50")
    sl.markdown(body = " —Ä–∞–∑, —á—Ç–æ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç $33.(3)$ % –æ—Ç `100`. ")

### ===============
def u_test(DF, sel_col_A_name, sel_col_B_name):
# 3. Mann-Whitney U-test
    sl.divider()
    ##
    is_cat_sel_col_A = is_Categorial(DF, sel_col_A_name)
    is_cat_sel_col_B = is_Categorial(DF, sel_col_B_name)
    if ((is_cat_sel_col_A or is_cat_sel_col_B) == True):
        sl.write(":red[**InPut Error:** Please, select both non-Categorical Data-Frame Columns of the _2_!]")
    else:
    ####
        #sel_col_A_name = DF_cols_names[sel_col_A_i]
        sl.write("Column A =", sel_col_A_name)
        vals_A = DF[sel_col_A_name]

        #sel_col_B_name = DF_cols_names[sel_col_B_i]
        sl.write("Column B =", sel_col_B_name)
        vals_B = DF[sel_col_B_name]

        stat, p_value = mannwhitneyu(vals_A,  vals_B)
        sl.write(f"=> **Mann-Whitney U-Test:** \n - **statistic** \t= {stat:.4f}, \n - **p-value** \t= {p_value:.4f};")

### ===============

def chisq_test(DF, sel_col_A_name, sel_col_B_name):
# 5. Chi-Square-test
    sl.divider()
    ##
    is_cat_sel_col_A = is_Categorial(DF, sel_col_A_name)
    is_cat_sel_col_B = is_Categorial(DF, sel_col_B_name)
    if ((is_cat_sel_col_A or is_cat_sel_col_B) == True):
        sl.write(":red[**InPut Error:** Please, select both non-Categorical Data-Frame Columns of the _2_!]")
    else:
    ####
        #sel_col_A_name = DF_cols_names[sel_col_A_i]
        sl.write("Column A =", sel_col_A_name)
        vals_A = DF[sel_col_A_name]

        #sel_col_B_name = DF_cols_names[sel_col_B_i]
        sl.write("Column B =", sel_col_B_name)
        vals_B = DF[sel_col_B_name]

        data = [vals_A, vals_B]
        chisq, pvalue, df, expected = stats.chi2_contingency(data)
        sl.write(f"=> Chi-Square Test: \n - Observed Chi-Square \t= {chisq:.4f}, \n - p-value \t\t= {pvalue:.4f};")
        # + Resampled p-value = ???

### ===============
def stat_hip(DF, sel_col_1_name, sel_col_2_name):
    sl.divider()
    sl.header("Steps _4-5_. ‚ùî")
    sl.write("**Using Hypothesis Testing Algorithms:**")    
    sl.text("...")
    
    test_1_name = "Mann-Whitney U-Test"
    test_2_name = "Chi-Square Test"
    tests_names_list = [test_1_name, test_2_name]
    
    ### = Drop-Down _1_
    sel_test_name = sl.selectbox(label = "**Test:**", options = tests_names_list)
    if (sel_test_name == test_1_name):
        u_test(DF, sel_col_1_name, sel_col_2_name)
    elif (sel_test_name == test_2_name):
        chisq_test(DF, sel_col_1_name, sel_col_2_name)

### ===============
def summary_2():
    sl.divider()
    sl.markdown(body = "**–í—ã–≤–æ–¥—ã (2):**")
    sl.markdown(body = "**0.0 –ì–∏–ø–æ—Ç–µ–∑—ã:**")
    sl.markdown(body = "- $H_0$ **(_0_-—è):**          _2_ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã;")
    sl.markdown(body = "- $H_1$ **(–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è):** _2_ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–º–∏.")
    sl.markdown(body = "**0.1 –¢–µ—Å—Ç—ã:**")
    sl.markdown(body = "- **U-–∫—Ä–∏—Ç–µ—Ä–∏–π –ú–∞–Ω–Ω–∞-–£–∏—Ç–Ω–∏ (= –ö—Ä–∏—Ç–µ—Ä–∏–π —Å—É–º–º—ã —Ä–∞–Ω–≥–æ–≤ –£–∏–ª–∫–æ–∫—Å–æ–Ω–∞)** **–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è**:")
    sl.markdown(body = "-- `statistic`: The Mann-Whitney U statistic corresponding with sample x.")
    sl.markdown(body = "-- `pvalue`: The associated p-value for the chosen alternative.")
    sl.markdown(body = "- **–ö—Ä–∏—Ç–µ—Ä–∏–π —Å–æ–≥–ª–∞—Å–∏—è –ü–∏—Ä—Å–æ–Ω–∞ (= –¢–µ—Å—Ç $œá^2$, –Ω–∞ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å)** **–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è**:")
    sl.markdown(body = "-- `statistic`: The test statistic.")
    sl.markdown(body = "-- `pvalue`: The p-value of the test.")
    sl.markdown(body = "-- `dof`: The degrees of freedom.")
    sl.markdown(body = "-- `expected_freq`: The expected frequencies, based on the marginal sums of the table.")
    sl.markdown(body = "**=>**")
    sl.markdown(body = "`p-value` -- —ç—Ç–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É–≤–∏–¥–µ—Ç—å –≤ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è—Ö —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É –≥—Ä—É–ø–ø–∞–º–∏.")
    sl.markdown(body = "- –ï—Å–ª–∏ `p`-–∑–Ω–∞—á–µ–Ω–∏–µ —Ç–µ—Å—Ç–∞ `–Ω–µ –º–µ–Ω—å—à–µ` (—Ç. –µ. `–±–æ–ª—å—à–µ —Ä–∞–≤–Ω–æ`) `0,05`, –º—ã –Ω–µ –º–æ–∂–µ–º –æ—Ç–≤–µ—Ä–≥–Ω—É—Ç—å `0`-—é –≥–∏–ø–æ—Ç–µ–∑—É.")
    sl.markdown(body = "(–≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ —É –Ω–∞—Å –Ω–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã—Ö –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤, —á—Ç–æ–±—ã —Å–∫–∞–∑–∞—Ç—å, —á—Ç–æ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç —Å–≤—è–∑—å –º–µ–∂–¥—É `2`–º—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏.)")
    sl.markdown(body = "- –ò –Ω–∞–æ–±–æ—Ä–æ—Ç: –µ—Å–ª–∏ `p`-–∑–Ω–∞—á–µ–Ω–∏–µ `–º–µ–Ω—å—à–µ` `0,05`, –º—ã —Ç–æ—á–Ω–æ –æ—Ç–≤–µ—Ä–≥–∞–µ–º `0`-—é –≥–∏–ø–æ—Ç–µ–∑—É.")
    
    sl.text("...")
    
### ===============
def main():
    begin_Visualization()
    load_DF() 
    # <-- select_DF_cols(DF, DF_cols_names);
    # <-- plot_Distribution();
    # <-- if_Charts_or_Hist(DF, sel_col__name, is_cat_sel_col);
    # <-- plot_Charts(DF, sel_col_name) || plot_Hist(DF, sel_col_name) ;
    # <-- summary_1();
    # <-- stat_hip();
    # <-- u_test(DF, sel_col_A_name, sel_col_B_name) / ;
    summary_2(); #

main()